---
layout: default
title: Dogmatism Through the Lens of Memory: The Unreliability of Past Events in Shaping Our Worldview
---

# Dogmatism Through the Lens of Memory: The Unreliability of Past Events in Shaping Our Worldview

_On the Ability to Memorize and How Our Thinking Becomes More Dogmatic Over Time Due to Mental Images and Goals Mistaken for the Actual World_

Practitioners of mnemonics have long understood that the easiest way to remember a collection of unconnected pieces of information is to just make up some connections between them. This is because our brains cannot capture raw perception data --- they can only capture mental images and causal connections i.e. we only remember events that are connected with one another.

> 0.  Because we necessarily see them as connected, all events that we remember form a structure known as a causal chain.

An event that has nothing to do with our causal chain is simply not perceived by us (or, if perceived, it is not remembered even for a second). In many ways, placing the event in the causal chain is perception itself.

However, since we humans have only one causal chain — that is, we do not have multiple ways to perceive a given collection of events that we can switch between, putting an event on the causal chain also means replacing it with a mental image.

> 1.  Due to the way memories work, mental images reinforce themselves over time --- having the image of `A ⇒ B` in our minds, we would see `A`-s and `B`-s all over the place.

One of the biggest biases in our perception of time, which we have already discussed, is our inability to differentiate between the mental images representing the world (`M`) and the world itself (`W`). This results in us thinking that our perceptions represent the state of affairs, whereas they are merely a record of our mental images. Memories are probably the chief reason for this bias, as they can multiply it indefinitely: the moment we perceive a given "frame," the memory of it is rich in sensory (empirical) data, which can be further analyzed and interpreted. But as soon as we perceive the next frame, many aspects of the previous one are compressed, leaving only those that provide context for the next frame. Then, when a third frame is perceived, the two we already have are packaged together again, leaving only the aspects useful for the perception of the third frame. The problem is that _there isn't a way to know which aspects will actually be useful for providing context in the future_.

Like causality, we naively think of our memories as true representations of reality because they "work," i.e. because they have a good success rate at predicting future events. However, as with any other mental image, we do not have a clear criterion for what it means for memories to "work". Like any other mental image, memories represent an interpretation of reality, but they are also immutable. Once an event in the past is categorized under a mental image, let's say `A`, it cannot be taken to mean anything else than `A`, even if we start using better and more accurate mental images for such events in the future.

> 3.  The interpretation of past events cannot be modified, and different interpretations cannot be compared with one another, as the raw perceptive data is lost when details of the event are forgotten. Let's say we experience an event that we label `A` at time `T1`, and then later, at time `T2`, we "upgrade" our understanding and categorize the same class of events under a new related mental image — `A'`. (We can think of `A'` as better and more accurate, although whether it is so is actually irrelevant for our example.) Although this upgrade in our worldview would affect all future events, it would not change how the event experienced at time `T1` is categorized—it will still be `A`. Because sensory data is lost, there would be no way for us to know whether it was actually `A'` or not.

In other words, past events that we remember are mere projections of the mental images we used at that instant. They are as unstable and as subject to change as our future projections.

Furthermore, events that are part of the causal chain can be compressed further by imposing additional structure over time. For example, if I remember that I went to school yesterday, I do not remember going out of the house, locking the door, waiting for the bus, etc., as all of this is implicit. (Some computer compression algorithms are based on the same principle.) This compression process repeats more and more as our memories age. For instance, in ten years, you wouldn't remember every day you spent at school, you'd just have a very abstract image of the time you spent there. However, this compression algorithm is "lossy" — meaning that over time, our memories become more and more abstract. We remember less and less of what really happened in the form of actual events and more in the form of abstract mental images.

The more abstract a concept, memory, or mental image is, the less _real_ it is (or rather, the less it has to do with the concept of realness). However, because memories are images and not raw perception data, we cannot modify our perception of past events. The more distant an event is, the more abstract and "stylized" it becomes, i.e., connected with the mental images we used when we perceived it. Because of this, we cannot use our memories to create any _new_ mental images, only to extrapolate on the images we already have. This is why older people tend to be more dogmatic than younger people—we accumulate more mental images with time and, therefore, perceive less. The only way to prevent this is to have no memories at all.

## The Default Interpretation

We showed that memories are a very unreliable source for understanding reality, unreliability that we should take into account when making any conclusions based on them. However, as humans, our stance is not like this, as many of these images are deeply embedded in our minds.

It is often said that the definition of insanity is doing the same thing over and over and expecting different results. This saying clearly embodies one of the main (if not _the_ main) postulates of all human societies. In just a few words, it describes both the function that all people have in society (making the world behave uniformly for everyone) and what to do with those who refuse to participate in that task (label them as "insane," i.e., exclude them from it).
In reality, this principle is not entirely true.

For example, Suppose I experience something that brings me positive emotions (e.g. consume some tasty food). According to this principle, I would associate those emotions with the thing (or more precisely, with its appearance) and strive to repeat that experience to achieve the same result ( i.e. I would think that "more is better,") But obviously this doesn't work. So perhaps a more fitting definition of insanity would be --- doing the same thing over and over and expecting _similar_ results all the time.

Someone might argue that the example is simplistic and that anyone in their right mind would know when to stop eating. However, I would argue that the reality is that most of us do not know (or we know in theory but not in practice). And that even this basic and seemingly obvious fallacy is something we struggle to grasp, and I believe it is enough to illustrate my point. Thoughts like "more is better" are an inherent defect of the law of causality and the way we perceive the world, and they cannot be removed without undermining causality itself.

## References

- Nassim Taleb often deals with the human inability to see and account for uncertainty.
- Marshall McLuhan discusses the cultural aspect of our worldview in his book _Understanding Media_.
